# Parallelize Classic Sorting Algorithm: Quick Sort

This repository explores various parallel methods to accelerate the QuickSort algorithm. The goal is to leverage parallel computing techniques to enhance the performance of QuickSort. Different parallelization approaches, such as std::thread, OpenMP, and MPI, are implemented and compared.

## Introduction
QuickSort is a widely used sorting algorithm known for its efficiency. However, its performance can be further improved by exploiting parallel processing capabilities. This repository aims to experiment with various parallelization methods to accelerate QuickSort and provide insights into their effectiveness.

## Implemented Methods
1. std::thread: Utilizes C++ standard library threads to parallelize QuickSort.
    * `quicksort_std_thread`: Implements a  divide-and-conquer parallelization strategy using std::thread.
    * `quicksort_std_thread_m`: Splits data into many parts first, QuickSorts them with std::thread, and then merges them.

2. OpenMP: Implements parallelization using OpenMP directives to distribute the workload among multiple threads.

    * `quicksort_omp`: Implements a  divide-and-conquer parallelization strategy using OpenMP.
    * `quicksort_omp_m`: Splits data into many parts first, QuickSorts them with OpenMP, and then merges them.
3. MPI (Message Passing Interface): Explores parallelization across distributed systems using MPI.
    * `quicksort_mpi`: Implements a  divide-and-conquer parallelization strategy using MPI.
    * `quicksort_mpi_m`: Splits data into many parts first, QuickSorts them with MPI, and then merges them. (Requires a hosts file for MPI configuration.)
4. CUDA:     * `quicksort_mpi`: Implements a  divide-and-conquer parallelization strategy using CUDA. Note: There is a known flaw in this CUDA implementation that may produce incorrect results for large datasets.

## Getting Started
To get started, clone the repository to the PP machine:
```bash
git clone https://github.com/benebsiny/PP-final.git
cd PP-final
```

Use make to compile the executables:
```bash
make
```

## Generating Test Data
To generate test data, use the following command:
```bash
./helpers/gen_testcase [number of data to create]
```

## Usage

|Program|Command|
|---|---|
|Basic QuickSort|	./quicksort \<input file>|
|std::thread|./quicksort_std_thread \<input file> [number of threads] [threshold]|
|std::thread with merging|./quicksort_std_thread_m \<input file> [number of threads]|
|OpenMP|./quicksort_omp \<input file> [number of threads] [threshold]|
|OpenMP with merging|./quicksort_omp_m \<input file> [number of threads]|
|MPI |	mpirun -np \<number of processes> --hostfile hosts quicksort_mpi \<input file> [threshold]|
|MPI with merging|mpirun -np \<number of processes> --hostfile hosts quicksort_mpi_m \<input file>|
|CUDA|./quicksort_cuda \<input file\>|

### Note
* \<input file\>: A file generated by the `gen_testcase` script.
* \<number of threads\>: The number of threads to be executed.
* \<number of processes\>: The number of processes to be executed.
* \<threshold\>:
    * Threshold parameter is optional and only applicable to the std::thread and OpenMP implementations. 
    * It represents the minimum size of a partition for which a new thread is created during the sorting process
    * When specified, if the number of elements in a partition is smaller than 1/\<threshold\> of the total data, a new thread won't be created. Instead, the partition will be processed in the current thread.
    * If not specified, the algorithm may result in workload imbalances between threads or processes. The decision to create new threads or processes will depend on the default behavior of the parallelization method used.

## Reproduce
There is a file `reproduce.sh` to reproduce the results in the report. Remember to create a file `hosts` containing the host names for MPI before executing it.
```bash
./reproduce.sh
```
